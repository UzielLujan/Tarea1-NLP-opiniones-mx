# Procesamiento de Texto e Imagenes con Deep Learning

# üìö Tarea 1 ‚Äî An√°lisis integral de corpus en espa√±ol

Este repositorio contiene la implementaci√≥n de un **pipeline completo de Procesamiento de Lenguaje Natural (NLP)** aplicado a un corpus en espa√±ol con 5 clases.  
El proyecto forma parte de la **Maestr√≠a en C√≥mputo Estad√≠stico** y cubre desde an√°lisis descriptivo hasta representaciones vectoriales y clasificaci√≥n supervisada.

---

## Objetivo
Aplicar un pipeline integral de NLP para:
- Analizar y describir corpus en espa√±ol.
- Evaluar leyes emp√≠ricas del lenguaje (ej. Ley de Zipf).
- Explorar estructuras l√©xicas y gramaticales.
- Construir representaciones (BoW, TF-IDF, Word2Vec).
- Realizar clustering, clasificaci√≥n y an√°lisis de t√≥picos.
- Explicar resultados con evidencia cuantitativa y visual.

---

## üìÇ Estructura del proyecto
```bash
Tarea1_NLP-opiniones-mx/
‚îÇ‚îÄ‚îÄ data/                 # Corpus y datos procesados
‚îÇ   ‚îú‚îÄ‚îÄ raw/              # Corpus original
‚îÇ   ‚îú‚îÄ‚îÄ interim/          # Datos intermedios (tokens, embeddings)
‚îÇ   ‚îî‚îÄ‚îÄ processed/        # Datos listos para modelado
‚îÇ
‚îÇ‚îÄ‚îÄ src/                  # C√≥digo fuente en m√≥dulos
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/    # Limpieza, stopwords, tokenizaci√≥n, stemming
‚îÇ   ‚îú‚îÄ‚îÄ analysis/         # Estad√≠sticas descriptivas, Ley de Zipf, hapax
‚îÇ   ‚îú‚îÄ‚îÄ representaciones/ # BoW, TF-IDF, bigramas, selecci√≥n de caracter√≠sticas
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/       # Word2Vec, doc embeddings
‚îÇ   ‚îú‚îÄ‚îÄ modeling/         # Clasificaci√≥n (SVM, Regresi√≥n Log√≠stica)
‚îÇ   ‚îú‚îÄ‚îÄ clustering/       # K-means, an√°lisis de cl√∫steres
‚îÇ   ‚îú‚îÄ‚îÄ topics/           # LSA con 50 t√≥picos
‚îÇ   ‚îî‚îÄ‚îÄ visualization/    # Gr√°ficas y utilidades
‚îÇ
‚îÇ‚îÄ‚îÄ notebooks/            # Experimentos y prototipos r√°pidos
‚îÇ
‚îÇ‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ figures/          # Im√°genes generadas
‚îÇ   ‚îî‚îÄ‚îÄ Tarea1_Reporte.pdf
‚îÇ
‚îÇ‚îÄ‚îÄ tests/                # Unit tests para funciones clave
‚îÇ
‚îÇ‚îÄ‚îÄ requirements.txt      # Dependencias
‚îÇ‚îÄ‚îÄ README.md             # Documentaci√≥n del proyecto
‚îÇ‚îÄ‚îÄ main.py               # Script principal que ejecuta el pipeline completo

```
## Entorno reproducible

Para correr este proyecto localmente, usar el entorno `conda` definido en `environment.yml`.

### Crear entorno desde cero

```bash
conda env create -f environment.yml
conda activate tarea1-nlp
```
## Ejecutar el pipeline completo
Para ejecutar el pipeline completo, correr:
```bash
python main.py --pipeline_completo
```

## Algunos comandos para ejecutar el pipeline por partes

0. Estad√≠sticas generales del corpus
```bash
python main.py --estadisticas
```

1. Analizar Ley de Zipf sin stopwords y con top_n=100:
```bash
python main.py --zipf --sin_stopwords --top_n 100
```

2. Generar palabras frecuentes y 4-gramas POS:
```bash
python main.py --frecuentes --pos
```
3. Entrenar Word2Vec y correr analog√≠as:
```bash
python main.py --word2vec
```
4. Crear BoW y TF-IDF con bigramas y min_df=10:
```bash
python main.py --bow --min_df 10 --ngram_max 2
```

5. Visualizar representacion vectoriales con PCA
```bash
python main.py --pca --pca_tipo pkl --pca_path data/interim/bow_vectorizer.pkl --pca_title "PCA BoW"
python main.py --pca --pca_tipo pkl --pca_path data/interim/tdidf_vectorizer.pkl --pca_title "PCA TDiDF"
python main.py --pca --pca_tipo model --pca_path data/interim/word2vec.model --pca_title "PCA Word2Vec"
python main.py --pca --pca_tipo npy --pca_path data/interim/doc_embeddings.npy --pca_title "PCA Doc Embeddings"
```
6. Ejecutar clasificacion (Regresi√≥n Log√≠stica) con diferentes niveles de preprocesamiento:
```bash
python main.py --clasificacion
``` 

7. Ejecutar solo LSA:
```bash
python main.py --lsa
```
> **Nota:** Para consultar la lista completa de comandos y ejemplos de uso del pipeline por m√≥dulos, revisa el archivo [`argparse_commands.md`](./argparse_commands.md).