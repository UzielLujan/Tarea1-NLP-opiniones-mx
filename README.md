# Procesamiento de Texto e Imagenes con Deep Learning

# ğŸ“š Tarea 1 â€” AnÃ¡lisis integral de corpus en espaÃ±ol

Este repositorio contiene la implementaciÃ³n de un **pipeline completo de Procesamiento de Lenguaje Natural (NLP)** aplicado a un corpus en espaÃ±ol con 5 clases.  
El proyecto forma parte de la **MaestrÃ­a en CÃ³mputo EstadÃ­stico** y cubre desde anÃ¡lisis descriptivo hasta representaciones vectoriales y clasificaciÃ³n supervisada.

---

## ğŸ¯ Objetivo
Aplicar un pipeline integral de NLP para:
- Analizar y describir corpus en espaÃ±ol.
- Evaluar leyes empÃ­ricas del lenguaje (ej. Ley de Zipf).
- Explorar estructuras lÃ©xicas y gramaticales.
- Construir representaciones (BoW, TF-IDF, Word2Vec).
- Realizar clustering, clasificaciÃ³n y anÃ¡lisis de tÃ³picos.
- Explicar resultados con evidencia cuantitativa y visual.

---

## ğŸ“‚ Estructura del proyecto
```bash
Tarea1_NLP-opiniones-mx/
â”‚â”€â”€ data/                 # Corpus y datos procesados
â”‚   â”œâ”€â”€ raw/              # Corpus original
â”‚   â”œâ”€â”€ interim/          # Datos intermedios (tokens, embeddings)
â”‚   â””â”€â”€ processed/        # Datos listos para modelado
â”‚
â”‚â”€â”€ src/                  # CÃ³digo fuente en mÃ³dulos
â”‚   â”œâ”€â”€ preprocessing/    # Limpieza, stopwords, tokenizaciÃ³n, stemming
â”‚   â”œâ”€â”€ analysis/         # EstadÃ­sticas descriptivas, Ley de Zipf, hapax
â”‚   â”œâ”€â”€ features/         # BoW, TF-IDF, bigramas, selecciÃ³n de caracterÃ­sticas
â”‚   â”œâ”€â”€ embeddings/       # Word2Vec, doc embeddings
â”‚   â”œâ”€â”€ modeling/         # ClasificaciÃ³n (SVM, RegresiÃ³n LogÃ­stica)
â”‚   â”œâ”€â”€ clustering/       # K-means, anÃ¡lisis de clÃºsteres
â”‚   â”œâ”€â”€ topics/           # LSA con 50 tÃ³picos
â”‚   â””â”€â”€ visualization/    # GrÃ¡ficas y utilidades
â”‚
â”‚â”€â”€ notebooks/            # Experimentos y prototipos rÃ¡pidos
â”‚
â”‚â”€â”€ reports/
â”‚   â”œâ”€â”€ figures/          # ImÃ¡genes generadas
â”‚   â””â”€â”€ Tarea1_Reporte.pdf
â”‚
â”‚â”€â”€ tests/                # Unit tests para funciones clave
â”‚
â”‚â”€â”€ requirements.txt      # Dependencias
â”‚â”€â”€ README.md             # DocumentaciÃ³n del proyecto
â”‚â”€â”€ main.py               # Script principal que ejecuta el pipeline completo

```
## ğŸ› ï¸ Entorno reproducible

Para correr este proyecto localmente, usar el entorno `conda` definido en `environment.yml`.

### ğŸ” Crear entorno desde cero

```bash
conda env create -f environment.yml
conda activate tarea1-nlp
```


## ğŸ§ª Ejecutar el pipeline por partes

1. Analizar Ley de Zipf sin stopwords y con top_n=100:
```bash
python main.py --zipf --sin_stopwords --top_n 100
```

2. Generar palabras frecuentes y 4-gramas POS:
```bash
python main.py --frecuentes --pos
```
3. Entrenar Word2Vec y correr analogÃ­as:
```bash
python main.py --word2vec
```
4. Crear BoW y TF-IDF con bigramas y min_df=10:
```bash
python main.py --bow --min_df 10 --ngram_max 2
```

5. Ejecutar solo LSA:
```bash
python main.py --lsa
```